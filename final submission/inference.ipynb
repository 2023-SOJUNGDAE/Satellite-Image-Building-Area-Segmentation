{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"PmdWnBHkLMa2"},"outputs":[],"source":["# 각 셀(각 모델)을 돌려 inference 하기 전에 무조건 돌여야 하는 셀\n","\n","import torch\n","import cv2\n","import pandas as pd\n","import numpy as np\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from tqdm import tqdm\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","torch.cuda.set_device(0)\n","\n","# RLE 디코딩 함수\n","def rle_decode(mask_rle, shape):\n","    s = mask_rle.split()\n","    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n","    starts -= 1\n","    ends = starts + lengths\n","    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n","    for lo, hi in zip(starts, ends):\n","        img[lo:hi] = 1\n","    return img.reshape(shape)\n","\n","def rle_decode_prob(mask_rle, shape):\n","    s = mask_rle.split()\n","    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n","    values = np.asarray(s[2:][::2], dtype=float)\n","    starts -= 1\n","    ends = starts + lengths\n","    img = np.zeros(shape[0]*shape[1], dtype=np.float32)\n","    value_idx = 0\n","    for lo, hi in zip(starts, ends):\n","        img[lo:hi] = values[value_idx]\n","        value_idx += 1\n","    return img.reshape(shape)\n","\n","\n","# RLE 인코딩 함수\n","def rle_encode(mask):\n","    pixels = mask.flatten()\n","    pixels = np.concatenate([[0], pixels, [0]])\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n","    runs[1::2] -= runs[::2]\n","    return ' '.join(str(x) for x in runs)\n","\n","# 기존 dataloader - testdata 로딩에 사용\n","class SatelliteDataset1(Dataset):\n","    def __init__(self, csv_file, transform=None, infer=False):\n","        self.data = pd.read_csv(csv_file)\n","        self.transform = transform\n","        self.infer = infer\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.data.iloc[idx, 1]\n","        image = cv2.imread(img_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        if self.infer:\n","            if self.transform:\n","                image = self.transform(image=image)['image']\n","            return image\n","\n","        mask_rle = self.data.iloc[idx, 2]\n","        mask = rle_decode(mask_rle, (image.shape[0], image.shape[1]))\n","\n","        if self.transform:\n","            augmented = self.transform(image=image, mask=mask)\n","            image = augmented['image']\n","            mask = augmented['mask']\n","\n","        return image, mask\n","\n","transform1 = A.Compose(\n","    [\n","        A.Resize(224, 224),\n","        A.Normalize(),\n","        ToTensorV2()\n","    ]\n",")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"prqIQwo_4wLo"},"outputs":[],"source":["# upernet-convnext-xlarge\n","\n","test_dataset = SatelliteDataset1(csv_file='test.csv', transform=transform1, infer=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)\n","\n","# # (저장된 모델이 있다면) 모델 weights 불러오기\n","\n","\n","from transformers import AutoImageProcessor, UperNetForSemanticSegmentation\n","\n","\n","model = UperNetForSemanticSegmentation.from_pretrained(\n","    \"openmmlab/upernet-convnext-xlarge\", num_labels=1, ignore_mismatched_sizes=True\n",").to(device)\n","\n","model.load_state_dict(torch.load(\"weights/upernet_convNext_xlarge.pth\"))\n","\n","\n","\n","masksarr = []\n","with torch.no_grad():\n","    model.eval()\n","    result = []\n","    num_images = 0\n","    for images in tqdm(test_dataloader):\n","        images = images.float().to(device)\n","\n","        outputs = model(images).logits\n","        masks = torch.sigmoid(outputs).cpu().numpy()\n","        masksarr.append(masks)\n","        masks = np.squeeze(masks, axis=1)\n","        masks = (masks > 0.55).astype(np.uint8) # Threshold\n","\n","        for i in range(len(images)):\n","            mask_rle = rle_encode(masks[i])\n","            if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1\n","                result.append(-1)\n","            else:\n","                result.append(mask_rle)\n","\n","            num_images += 1\n","\n","submit = pd.read_csv('data/sample_submission.csv')\n","submit['mask_rle'] = result\n","submit.to_csv('uper_convnext_xlarge_mask_0.55.csv', index=False)\n","\n","model = model.to(\"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AgjMwp_p4wLp"},"outputs":[],"source":["# unet-convnext-xlarge\n","\n","test_dataset = SatelliteDataset1(csv_file='test.csv', transform=transform1, infer=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)\n","\n","# # (저장된 모델이 있다면) 모델 weights 불러오기\n","\n","from backbones_unet.model.unet import Unet\n","model = Unet(\n","    backbone='convnext_xlarge_in22ft1k',\n","    in_channels=3,\n","    num_classes=1,\n",").to(device=device)\n","\n","\n","model.load_state_dict(torch.load(\"weights/unet_convNext_xlarge_final.pth\"))\n","\n","masksarr = []\n","with torch.no_grad():\n","    model.eval()\n","    result = []\n","    num_images = 0\n","    for images in tqdm(test_dataloader):\n","        images = images.float().to(device)\n","\n","        outputs = model(images)\n","        masks = torch.sigmoid(outputs).cpu().numpy()\n","        masksarr.append(masks)\n","        masks = np.squeeze(masks, axis=1)\n","        masks = (masks > 0.55).astype(np.uint8) # Threshold\n","\n","        for i in range(len(images)):\n","            mask_rle = rle_encode(masks[i])\n","            if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1\n","                result.append(-1)\n","            else:\n","                result.append(mask_rle)\n","\n","            num_images += 1\n","\n","submit = pd.read_csv('data/sample_submission.csv')\n","submit['mask_rle'] = result\n","submit.to_csv('unet_convnext_xlarge_mask_0.55.csv', index=False)\n","model = model.to(\"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qbY2jT_94wLq"},"outputs":[],"source":["# unet-convnext-large\n","\n","test_dataset = SatelliteDataset1(csv_file='test.csv', transform=transform1, infer=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)\n","\n","# # (저장된 모델이 있다면) 모델 weights 불러오기\n","\n","from backbones_unet.model.unet import Unet\n","model = Unet(\n","    backbone='convnext_large_in22ft1k',\n","    in_channels=3,\n","    num_classes=1,\n",").to(device=device)\n","\n","\n","model.load_state_dict(torch.load(\"weights/unet_convNext_large_final.pth\"))\n","\n","masksarr = []\n","with torch.no_grad():\n","    model.eval()\n","    result = []\n","    num_images = 0\n","    for images in tqdm(test_dataloader):\n","        images = images.float().to(device)\n","\n","        outputs = model(images)\n","        masks = torch.sigmoid(outputs).cpu().numpy()\n","        masksarr.append(masks)\n","        masks = np.squeeze(masks, axis=1)\n","        masks = (masks > 0.6).astype(np.uint8) # Threshold\n","\n","        for i in range(len(images)):\n","            mask_rle = rle_encode(masks[i])\n","            if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1\n","                result.append(-1)\n","            else:\n","                result.append(mask_rle)\n","\n","            num_images += 1\n","submit = pd.read_csv('data/sample_submission.csv')\n","submit['mask_rle'] = result\n","submit.to_csv('unet_convnext_large_mask_0.6.csv', index=False)\n","model = model.to(\"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YFwHXgF74wLq"},"outputs":[],"source":["# unet_convNext_base\n","\n","test_dataset = SatelliteDataset1(csv_file='test.csv', transform=transform1, infer=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)\n","\n","# # (저장된 모델이 있다면) 모델 weights 불러오기\n","\n","from backbones_unet.model.unet import Unet\n","model = Unet(\n","    backbone='convnext_base_in22ft1k',\n","    in_channels=3,\n","    num_classes=1,\n",").to(device=device)\n","\n","\n","model.load_state_dict(torch.load(\"weights/unet_convNext_base_final.pth\"))\n","\n","masksarr = []\n","with torch.no_grad():\n","    model.eval()\n","    result = []\n","    num_images = 0\n","    for images in tqdm(test_dataloader):\n","        images = images.float().to(device)\n","\n","        outputs = model(images)\n","        masks = torch.sigmoid(outputs).cpu().numpy()\n","        masksarr.append(masks)\n","        masks = np.squeeze(masks, axis=1)\n","        masks = (masks > 0.6).astype(np.uint8) # Threshold\n","\n","        for i in range(len(images)):\n","            mask_rle = rle_encode(masks[i])\n","            if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1\n","                result.append(-1)\n","            else:\n","                result.append(mask_rle)\n","\n","            num_images += 1\n","\n","submit = pd.read_csv('data/sample_submission.csv')\n","submit['mask_rle'] = result\n","submit.to_csv('unet_convnext_base_mask_0.6.csv', index=False)\n","model = model.to(\"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kP0qABxZ4wLr"},"outputs":[],"source":["# uper_convnext_large\n","\n","test_dataset = SatelliteDataset1(csv_file='test.csv', transform=transform1, infer=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)\n","\n","# # (저장된 모델이 있다면) 모델 weights 불러오기\n","\n","from backbones_unet.model.unet import Unet\n","\n","from transformers import AutoImageProcessor, UperNetForSemanticSegmentation\n","model = UperNetForSemanticSegmentation.from_pretrained(f\"openmmlab/upernet-convnext-large\", num_labels=1, ignore_mismatched_sizes=True).to(device)\n","\n","\n","model.load_state_dict(torch.load(\"weights/upernet_convNext_large_final.pth\"))\n","\n","masksarr = []\n","with torch.no_grad():\n","    model.eval()\n","    result = []\n","    num_images = 0\n","    for images in tqdm(test_dataloader):\n","        images = images.float().to(device)\n","\n","        outputs = model(images).logits\n","        masks = torch.sigmoid(outputs).cpu().numpy()\n","        masksarr.append(masks)\n","        masks = np.squeeze(masks, axis=1)\n","        masks = (masks > 0.6).astype(np.uint8) # Threshold\n","\n","        for i in range(len(images)):\n","            mask_rle = rle_encode(masks[i])\n","            if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1\n","                result.append(-1)\n","            else:\n","                result.append(mask_rle)\n","\n","            num_images += 1\n","\n","submit = pd.read_csv('data/sample_submission.csv')\n","submit['mask_rle'] = result\n","submit.to_csv('uper_convnext_large_mask_0.6.csv', index=False)\n","model = model.to(\"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"znMWi25-4wLr"},"outputs":[],"source":["# 에피션트넷\n","\n","test_dataset = SatelliteDataset1(csv_file='test.csv', transform=transform1, infer=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)\n","\n","# # (저장된 모델이 있다면) 모델 weights 불러오기\n","\n","from backbones_unet.model.unet import Unet\n","model = Unet(\n","    backbone='tf_efficientnetv2_l_in21ft1k',\n","    in_channels=3,\n","    num_classes=1,\n",").to(device=device)\n","\n","model.load_state_dict(torch.load(\"weights/unet_efficientnetV2_l_final.pth\"))\n","\n","masksarr = []\n","with torch.no_grad():\n","    model.eval()\n","    result = []\n","    num_images = 0\n","    for images in tqdm(test_dataloader):\n","        images = images.float().to(device)\n","\n","        outputs = model(images)\n","        masks = torch.sigmoid(outputs).cpu().numpy()\n","        masksarr.append(masks)\n","        masks = np.squeeze(masks, axis=1)\n","        masks = (masks > 0.6).astype(np.uint8) # Threshold\n","\n","        for i in range(len(images)):\n","            mask_rle = rle_encode(masks[i])\n","            if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1\n","                result.append(-1)\n","            else:\n","                result.append(mask_rle)\n","\n","            num_images += 1\n","\n","submit = pd.read_csv('data/sample_submission.csv')\n","submit['mask_rle'] = result\n","submit.to_csv('unet_efficientnetV2_l_mask_0.6.csv', index=False)\n","model = model.to(\"cpu\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat":4,"nbformat_minor":0}